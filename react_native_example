# import libraies, using flask
from flask import Flask, request, jsonify
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
import numpy as np

app = Flask(__name__)

#dataset w features
data = [
    ("Alvie is great!", 1),
    ("This app didn't help me!", 0),
    ("Alvie changed my life. I love it!", 1),
    ("The app could be better, I'm gonna use Headspace instead.", 0)
]

#tokenizing sentences and convert to numerical data
sentences = [sentence for sentence, _ in data]
labels = [label for _, label in data]

tokenizer = Tokenizer(num_words=100, oov_token="<OOV>")
tokenizer.fit_on_texts(sentences)
word_index = tokenizer.word_index
sequences = tokenizer.texts_to_sequences(sentences)
padded_sequences = pad_sequences(sequences, padding='post')

#converting labels to numpy array
labels = np.array(labels)

# neural network model to be used
model = Sequential([
    Embedding(input_dim=100, output_dim=16, input_length=len(padded_sequences[0])),
    LSTM(32),
    Dense(16, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#training model
model.fit(padded_sequences, labels, epochs=10)

def predict_sentiment(model, post):
    sequence = tokenizer.texts_to_sequences([post])
    padded_sequence = pad_sequences(sequence, maxlen=len(padded_sequences[0]), padding='post')
    prediction = model.predict(padded_sequence)
    return prediction[0][0]

@app.route('/predict', methods=['POST'])
def predict():
    post = request.json.get('post')
    if not post:
        return jsonify({'error': 'No post provided'}), 400
    sentiment = predict_sentiment(model, post)
    return jsonify({'sentiment': float(sentiment)})

if __name__ == '__main__':
    app.run(debug=True)

