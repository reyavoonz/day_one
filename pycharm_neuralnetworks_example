#import packages and libraries like tensorflow for PyCharm and its keras API for neural networks
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
#neural network architecture for stacking of layers, text to num vectors, etc.
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
import numpy as np

#dataset- posts and sentiments (0=neg, 1=pos)
data = [
    ("Alvie is great!", 1),
    ("This app didn't help me!", 0),
    ("Alvie changed my life. I love it!", 1),
    ("The app could be better, I'm gonna use Headspace instead.", 0)
]

#extract sentences & labels from dataset
sentences = [sentence for sentence, _ in data]
labels = [label for _, label in data]

#tokenise text to numerical data
tokenizer = Tokenizer(num_words=100, oov_token="<OOV>") #max num of words
tokenizer.fit_on_texts(sentences) #internal data updated w these sentences
word_index = tokenizer.word_index
sequences = tokenizer.texts_to_sequences(sentences) #sentences to integers
padded_sequences = pad_sequences(sequences, padding='post') #uniform length of the integer sequences for NN

#convert labels to numpy array
labels = np.array(labels)

#define neural network model to be used
model = Sequential([
    Embedding(input_dim=100, output_dim=16, input_length=len(padded_sequences[0])), #each word represented by a vector
    LSTM(32),
    Dense(16, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])
#configure model w specific loss fucntion, quantifying how well model is performing
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#train  model, no. of complete passes
model.fit(padded_sequences, labels, epochs=10)

#test model with new post
def predict_sentiment(model, post):
    sequence = tokenizer.texts_to_sequences([post])
    padded_sequence = pad_sequences(sequence, maxlen=len(padded_sequences[0]), padding='post')
    prediction = model.predict(padded_sequence)
    return prediction[0][0]
#predict sentiment func for score on new post
new_post = "I really loved using Alvie! My fav app on the market!"
predicted_sentiment = predict_sentiment(model, new_post)
print(f"Predicted Sentiment for the new post '{new_post}': {predicted_sentiment:.4f}")
